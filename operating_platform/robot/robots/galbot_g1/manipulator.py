import asyncio
import json
import base64
import time
import os
import sys
import numpy as np
import cv2
import websockets
import threading
import logging
import torch
from typing import Any, Dict, Optional

os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(current_dir, 'galbot'))

from pathlib import Path
import sys

# # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼ˆé¡¹ç›®æ ¹ï¼‰
# project_root = Path(__file__).resolve().parent
# galbot_path = project_root / 'galbot'

# if str(galbot_path) not in sys.path:
#     sys.path.insert(0, str(galbot_path))

from galbot.core_proto import time_pb2, header_pb2
from galbot.spatial_proto import twist_pb2, pose_pb2
from galbot.singorix_proto import singorix_command_pb2, singorix_sensor_pb2, singorix_error_pb2, singorix_target_pb2
from galbot.sensor_proto import imu_pb2, image_pb2, camera_pb2, joy_pb2
from galbot.tf2_proto import tf2_message_pb2

from operating_platform.robot.robots.utils import RobotDeviceNotConnectedError
from operating_platform.robot.robots.galbot_g1.config import GalbotG1RobotConfig
from operating_platform.robot.robots.com_configs.cameras import CameraConfig, OpenCVCameraConfig, DDSCameraConfig
from operating_platform.robot.robots.camera import Camera

# æ—¥å¿—è®¾ç½®
try:
    from operating_platform.utils.colored_logging import setup_colored_logger
    logger = setup_colored_logger(__name__)
except Exception:
    logger = logging.getLogger(__name__)
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class AsyncLoopManager:
    """ç®¡ç†å¼‚æ­¥äº‹ä»¶å¾ªç¯çš„çº¿ç¨‹"""
    def __init__(self):
        self.loop = None
        self.thread = None
        self.running = False
        
    def start_loop(self):
        """åœ¨æ–°çº¿ç¨‹ä¸­å¯åŠ¨äº‹ä»¶å¾ªç¯"""
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        self.running = True
        self.loop.run_forever()
    
    def start(self):
        """å¯åŠ¨çº¿ç¨‹"""
        self.thread = threading.Thread(target=self.start_loop, daemon=True)
        self.thread.start()
        
        # ç­‰å¾…å¾ªç¯åˆå§‹åŒ–
        for _ in range(10):  # æœ€å¤šç­‰å¾…1ç§’
            if self.loop and self.loop.is_running():
                break
            time.sleep(0.1)
        else:
            raise RuntimeError("æ— æ³•å¯åŠ¨äº‹ä»¶å¾ªç¯")
    
    def stop(self):
        """åœæ­¢äº‹ä»¶å¾ªç¯å’Œçº¿ç¨‹"""
        if self.loop and self.loop.is_running():
            self.loop.call_soon_threadsafe(self.loop.stop)
            self.running = False
            if self.thread:
                self.thread.join(timeout=1.0)
    
    def run_coroutine(self, coro):
        """åœ¨äº‹ä»¶å¾ªç¯çº¿ç¨‹ä¸­è¿è¡Œåç¨‹"""
        if self.loop and self.loop.is_running():
            return asyncio.run_coroutine_threadsafe(coro, self.loop)
        else:
            raise RuntimeError("äº‹ä»¶å¾ªç¯æœªè¿è¡Œ")

class RobotSocket:
    def __init__(self, robot_ip, bridge_port=10800):
        self.robot_ip = robot_ip
        self.bridge_port = bridge_port
        self.ws = None
        self.uri = f"ws://{self.robot_ip}:{self.bridge_port}"
        self.task = None  # listen ä»»åŠ¡

        # å¼‚æ­¥å¾ªç¯ç®¡ç†å™¨
        self.loop_manager = AsyncLoopManager()

        # çŠ¶æ€å­˜å‚¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self.latest_states = {}
        self.state_lock = threading.Lock()

        # å›¾åƒç¼“å­˜ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self.latest_images = {}  # topic -> numpy array
        self.image_lock = threading.Lock()

        # æ–°å¢ï¼šç»“æ„åŒ–å­˜å‚¨ç‰¹å®šå…³èŠ‚ç»„æ•°æ®
        self.arm_joint_data = {
            "right_arm": {},
            "left_arm": {}
        }
        self.gripper_data = {
            "right_gripper": {},
            "left_gripper": {}
        }
        self.leg_data = {
            "leg": {},
        }
        self.head_data = {
            "head": {},
        }

        # Protobuf ç±»å‹æ˜ å°„
        self.protobuf_type_map = {
            "galbot.sensor_proto.CompressedImage": image_pb2.CompressedImage,
            "galbot.sensor_proto.CameraInfo": camera_pb2.CameraInfo,
            "galbot.singorix_proto.SingoriXSensor": singorix_sensor_pb2.SingoriXSensor,
            "galbot.singorix_proto.SingoriXError": singorix_error_pb2.SingoriXError,
            "galbot.singorix_proto.SingoriXTarget": singorix_target_pb2.SingoriXTarget,
            "galbot.tf2_proto.TF2Message": tf2_message_pb2.TF2Message,
            "galbot.sensor_proto.Joy": joy_pb2.Joy
        }

        # å¼‚æ­¥ä»»åŠ¡æ§åˆ¶
        self.running = False
        self.connection_event = threading.Event()

    def start(self):
        """å¯åŠ¨è¿æ¥ï¼ˆéé˜»å¡ï¼‰"""
        self.loop_manager.start()
        self.loop_manager.run_coroutine(self.connect())
        
        # ç­‰å¾…è¿æ¥å»ºç«‹æˆ–è¶…æ—¶
        if not self.connection_event.wait(timeout=10.0):
            raise ConnectionError("è¿æ¥æœºå™¨äººè¶…æ—¶")

    async def connect(self):
        """å»ºç«‹ WebSocket è¿æ¥"""
        try:
            self.ws = await websockets.connect(self.uri)
            logger.info(f"âœ… WebSocket å·²è¿æ¥: {self.uri}")
            self.running = True
            self.connection_event.set()
            self.task = asyncio.create_task(self.listen())
        except Exception as e:
            logger.error(f"âŒ è¿æ¥å¤±è´¥: {e}")
            self.connection_event.set()  # å³ä½¿å¤±è´¥ä¹Ÿè®¾ç½®äº‹ä»¶ï¼Œé¿å…é˜»å¡
            raise

    async def listen(self):
        """ç›‘å¬ WebSocket æ¶ˆæ¯"""
        try:
            async for message in self.ws:
                try:
                    msg_json = json.loads(message)
                    op = msg_json.get("op")

                    if op == "message":
                        await self._process_protobuf_message(msg_json)
                    elif op == "heartbeat":
                        await self._process_heartbeat(msg_json)
                    elif op == "error":
                        await self._process_error(msg_json)
                    else:
                        logger.debug(f"âš ï¸ æœªçŸ¥æ“ä½œç±»å‹: {op}")

                except json.JSONDecodeError:
                    logger.error(f"âŒ JSON è§£æå¤±è´¥: {message[:100]}...")
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

        except websockets.exceptions.ConnectionClosed as e:
            logger.info(f"ğŸ”Œ è¿æ¥å…³é—­: {e}")
        except Exception as e:
            logger.error(f"âŒ ç›‘å¬æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            self.running = False

    async def _process_protobuf_message(self, message):
        """å¤„ç† protobuf æ¶ˆæ¯"""
        topic = message.get("topic")
        type_str = message.get("type")
        data_b64 = message.get("data")

        if not all([topic, type_str, data_b64]):
            logger.error("âŒ ç¼ºå°‘å¿…è¦å­—æ®µ")
            return

        pb_class = self.protobuf_type_map.get(type_str)
        if not pb_class:
            logger.error(f"âŒ æœªçŸ¥ protobuf ç±»å‹: {type_str}")
            return

        try:
            data_bytes = base64.b64decode(data_b64)
            if not data_bytes:
                raise ValueError(f"è§£ç åå¾—åˆ°ç©ºå­—èŠ‚æ•°æ® (topic: {topic})")

            pb_message = pb_class()
            pb_message.ParseFromString(data_bytes)
            if pb_message is None:
                raise ValueError(f"åˆ›å»ºprotobufæ¶ˆæ¯å¯¹è±¡å¤±è´¥ (topic: {topic})")

            # å¤„ç†å›¾åƒï¼šç¼“å­˜åˆ° latest_imagesï¼Œä¸åœ¨è¿™é‡Œæ˜¾ç¤º
            if any(cam in topic for cam in [
                "/right_arm_camera/color/image_raw",
                "/left_arm_camera/color/image_raw",
                "/front_head_camera/right_color/image_raw",
                "/front_head_camera/left_color/image_raw"
            ]) and isinstance(pb_message, image_pb2.CompressedImage):
                np_arr = np.frombuffer(pb_message.data, np.uint8)
                image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
                if image is not None:
                    image = cv2.resize(image, (640, 480))
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    with self.image_lock:
                        self.latest_images[topic] = image

            # å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®
            elif "singorix/wbcs/sensor" in topic:
                self._parse_and_store_joint_data(pb_message)

            # é€šç”¨çŠ¶æ€å­˜å‚¨
            with self.state_lock:
                self.latest_states[topic] = {
                    "message": pb_message,
                    "timestamp": message.get("pub_ts", 0),
                    "received": time.time_ns()
                }

        except Exception as e:
            logger.error(f"âŒ è§£æ protobuf å¤±è´¥: {e}")

    async def _process_heartbeat(self, message):
        ts = message.get("ts", 0)
        logger.debug(f"ğŸ’“ å¿ƒè·³æ—¶é—´æˆ³: {ts}")

    async def _process_error(self, message):
        error_msg = message.get("msg", "æœªçŸ¥é”™è¯¯")
        logger.error(f"â— é”™è¯¯æ¶ˆæ¯: {error_msg}")

    def _parse_and_store_joint_data(self, sensor_msg):
        """è§£æ SingoriXSensor æ¶ˆæ¯ï¼Œæå–å¹¶å­˜å‚¨ arm å’Œ gripper æ•°æ®"""
        if not sensor_msg.joint_sensor_map:
            return

        with self.state_lock:
            for group_name, joint_sensor in sensor_msg.joint_sensor_map.items():
                n = len(joint_sensor.name)
                if n == 0:
                    continue

                joint_data = {}
                for i in range(n):
                    name = joint_sensor.name[i] if i < len(joint_sensor.name) else f"joint{i}"
                    joint_data[name] = {
                        "position": joint_sensor.position[i] if i < len(joint_sensor.position) else 0.0,
                        "velocity": joint_sensor.velocity[i] if i < len(joint_sensor.velocity) else 0.0,
                        "effort": joint_sensor.effort[i] if i < len(joint_sensor.effort) else 0.0,
                        "current": joint_sensor.current[i] if i < len(joint_sensor.current) else 0.0,
                    }

                if group_name == "right_arm":
                    self.arm_joint_data["right_arm"] = joint_data
                elif group_name == "left_arm":
                    self.arm_joint_data["left_arm"] = joint_data
                elif group_name == "right_gripper":
                    self.gripper_data["right_gripper"] = joint_data
                elif group_name == "left_gripper":
                    self.gripper_data["left_gripper"] = joint_data
                elif group_name == "leg":
                    self.leg_data["leg"] = joint_data
                elif group_name == "head":
                    self.head_data["head"] = joint_data

    def get_arm_state(self, side):
        key = f"{side}_arm"
        with self.state_lock:
            return self.arm_joint_data.get(key, {}).copy()

    def get_gripper_state(self, side):
        key = f"{side}_gripper"
        with self.state_lock:
            return self.gripper_data.get(key, {}).copy()

    def get_all_arm_states(self):
        with self.state_lock:
            return {k: v.copy() for k, v in self.arm_joint_data.items()}

    def get_all_gripper_states(self):
        with self.state_lock:
            return {k: v.copy() for k, v in self.gripper_data.items()}

    def get_latest_state(self, topic):
        with self.state_lock:
            return self.latest_states.get(topic)

    def get_all_topics(self):
        with self.state_lock:
            return list(self.latest_states.keys())

    def get_latest_image(self, topic):
        with self.image_lock:
            return self.latest_images.get(topic)

    def get_all_image_topics(self):
        with self.image_lock:
            return list(self.latest_images.keys())

    def shutdown(self):
        """å…³é—­è¿æ¥"""
        self.running = False
        if self.loop_manager:
            self.loop_manager.run_coroutine(self._async_shutdown())
            self.loop_manager.stop()

    async def _async_shutdown(self):
        """å¼‚æ­¥å…³é—­è¿æ¥"""
        if self.ws:
            await self.ws.close()
        if self.task and not self.task.done():
            self.task.cancel()
            try:
                await self.task
            except asyncio.CancelledError:
                pass
        logger.info("ğŸ”Œ WebSocket å·²å…³é—­")

class DDSOpenCVCamera:
    def __init__(self, config: DDSCameraConfig):
        self.config = config
        self.camera_index = config.camera_index
        self.port = None
        self.topic = config.topic

        # Store the raw (capture) resolution from the config.
        self.capture_width = config.width
        self.capture_height = config.height

        # If rotated by Â±90, swap width and height.
        if config.rotation in [-90, 90]:
            self.width = config.height
            self.height = config.width
        else:
            self.width = config.width
            self.height = config.height

        self.fps = config.fps
        self.channels = config.channels
        self.color_mode = config.color_mode
        self.mock = config.mock

        self.camera = None
        self.is_connected = False
        self.thread = None
        self.stop_event = None
        self.color_image = None
        self.logs = {}


def make_cameras_from_configs(camera_configs: dict[str, CameraConfig]) -> list[Camera]:
    cameras = {}

    for key, cfg in camera_configs.items():
        if cfg.type == "ddscamera":
            cameras[key] = DDSOpenCVCamera(cfg)
        else:
            raise ValueError(f"The camera type '{cfg.type}' is not valid.")

    return cameras


class GalbotG1Manipulator:
    def __init__(self, config: GalbotG1RobotConfig):
        self.config = config
        self.robot_type = self.config.type
        self.use_videos = self.config.use_videos
        self.microphones = self.config.microphones

        robot_ip = "127.0.0.1"
        self.robot_socket = RobotSocket(robot_ip)
        self.robot_socket.start()  # éé˜»å¡å¯åŠ¨

        # self.leader_motors = {}
        # self.leader_motors['main_leader'] = self.config.leader_arms["main"]

        self.follower_motors = {}
        self.follower_motors['right_arm'] = self.config.follower_motors["right_arm"]
        self.follower_motors['left_arm'] = self.config.follower_motors["left_arm"]
        self.follower_motors['right_gripper'] = self.config.follower_motors["right_gripper"]
        self.follower_motors['left_gripper'] = self.config.follower_motors["left_gripper"]
        self.follower_motors['leg'] = self.config.follower_motors["leg"]
        self.follower_motors['head'] = self.config.follower_motors["head"]

        self.cameras = make_cameras_from_configs(self.config.cameras)
        
        self.connect_excluded_cameras = ["image_pika_pose"]

        self.is_connected = False
        self.logs = {}

    def get_motor_names(self, arms: dict[str, dict]) -> list:
        return [f"{arm}_{motor}" for arm, bus in arms.items() for motor in bus.motors]

    @property
    def camera_features(self) -> dict:
        cam_ft = {}
        for cam_key, cam in self.cameras.items():
            key = f"observation.images.{cam_key}"
            cam_ft[key] = {
                "shape": (cam.height, cam.width, cam.channels),
                "names": ["height", "width", "channels"],
                "info": None,
            }
        return cam_ft
    
    @property
    def microphone_features(self) -> dict:
        mic_ft = {}
        for mic_key, mic in self.microphones.items():
            key = f"observation.audio.{mic_key}"
            mic_ft[key] = {
                "shape": (1,),
                "names": ["channels"],
                "info": None,
            }
        return mic_ft
    
    @property
    def motor_features(self) -> dict:
        action_names = self.get_motor_names(self.follower_motors)
        state_names = self.get_motor_names(self.follower_motors)
        return {
            "action": {
                "dtype": "float32",
                "shape": (len(action_names),),
                "names": action_names,
            },
            "observation.state": {
                "dtype": "float32",
                "shape": (len(state_names),),
                "names": state_names,
            },
        }
    
    def connect(self):
        timeout = 20  # ç»Ÿä¸€çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        start_time = time.perf_counter()

        # å®šä¹‰æ‰€æœ‰éœ€è¦ç­‰å¾…çš„æ¡ä»¶åŠå…¶é”™è¯¯ä¿¡æ¯
        conditions = [
            (
                lambda: all(camera.topic in self.robot_socket.get_all_image_topics() for name, camera in self.cameras.items() if name not in self.connect_excluded_cameras),
                lambda: [name for name, camera in self.cameras.items() if camera.topic not in self.robot_socket.get_all_image_topics()],
                "ç­‰å¾…æ‘„åƒå¤´å›¾åƒè¶…æ—¶"
            ),
            # (
            #     lambda: all(
            #         any(name in key for key in recv_joint)
            #         for name in self.leader_arms
            #     ),
            #     lambda: [name for name in self.leader_arms if not any(name in key for key in recv_joint)],
            #     "ç­‰å¾…ä¸»è‡‚å…³èŠ‚è§’åº¦è¶…æ—¶"
            # ),
            (
                lambda: all(
                    any(name in key for key in self.robot_socket.arm_joint_data)
                    or any(name in key for key in self.robot_socket.gripper_data)
                    or any(name in key for key in self.robot_socket.leg_data)
                    or any(name in key for key in self.robot_socket.head_data)
                    for name in self.follower_motors
                ),
                lambda: [
                    name for name in self.follower_motors
                    if not any(name in key for key in self.robot_socket.arm_joint_data)
                    and not any(name in key for key in self.robot_socket.gripper_data)
                    and not any(name in key for key in self.robot_socket.leg_data)
                    and not any(name in key for key in self.robot_socket.head_data)
                ],
                "ç­‰å¾…æœºå™¨äººå…³èŠ‚è§’åº¦è¶…æ—¶"
            ),
        ]

        # è·Ÿè¸ªæ¯ä¸ªæ¡ä»¶æ˜¯å¦å·²å®Œæˆ
        completed = [False] * len(conditions)

        while True:
            # æ£€æŸ¥æ¯ä¸ªæœªå®Œæˆçš„æ¡ä»¶
            for i in range(len(conditions)):
                if not completed[i]:
                    condition_func = conditions[i][0]
                    if condition_func():
                        completed[i] = True

            # å¦‚æœæ‰€æœ‰æ¡ä»¶éƒ½å·²å®Œæˆï¼Œé€€å‡ºå¾ªç¯
            if all(completed):
                break

            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.perf_counter() - start_time > timeout:
                failed_messages = []
                for i in range(len(completed)):
                    if not completed[i]:
                        condition_func, get_missing, base_msg = conditions[i]
                        missing = get_missing()

                        # é‡æ–°æ£€æŸ¥æ¡ä»¶æ˜¯å¦æ»¡è¶³ï¼ˆå¯èƒ½åˆšå¥½åœ¨æœ€åä¸€æ¬¡æ£€æŸ¥åæ»¡è¶³ï¼‰
                        if condition_func():
                            completed[i] = True
                            continue

                        # å¦‚æœæ²¡æœ‰ missingï¼Œä¹Ÿè§†ä¸ºæ»¡è¶³
                        if not missing:
                            completed[i] = True
                            continue

                        # è®¡ç®—å·²æ¥æ”¶çš„é¡¹
                        if i == 0:
                            received = [name for name in self.cameras if name not in missing]
                        else:
                            received = [name for name in self.follower_motors if name not in missing]

                        # æ„é€ é”™è¯¯ä¿¡æ¯
                        msg = f"{base_msg}: æœªæ”¶åˆ° [{', '.join(missing)}]; å·²æ”¶åˆ° [{', '.join(received)}]"
                        failed_messages.append(msg)

                # å¦‚æœæ‰€æœ‰æ¡ä»¶éƒ½å·²å®Œæˆï¼Œbreak
                if not failed_messages:
                    break

                # æŠ›å‡ºè¶…æ—¶å¼‚å¸¸
                raise TimeoutError(f"è¿æ¥è¶…æ—¶ï¼Œæœªæ»¡è¶³çš„æ¡ä»¶: {'; '.join(failed_messages)}")

            # å‡å°‘ CPU å ç”¨
            time.sleep(0.01)

        # ===== æ–°å¢æˆåŠŸæ‰“å°é€»è¾‘ =====
        success_messages = []
        # æ‘„åƒå¤´è¿æ¥çŠ¶æ€
        if conditions[0][0]():
            cam_received = [name for name, camera in self.cameras.items() 
                        if camera.topic in self.robot_socket.get_all_image_topics() and name not in self.connect_excluded_cameras]
            success_messages.append(f"æ‘„åƒå¤´: {', '.join(cam_received)}")

        # # ä¸»è‡‚æ•°æ®çŠ¶æ€
        # arm_data_types = ["ä¸»è‡‚å…³èŠ‚è§’åº¦",]
        # for i, data_type in enumerate(arm_data_types, 1):
        #     if conditions[i][0]():
        #         arm_received = [name for name in self.leader_arms 
        #                     if any(name in key for key in (recv_joint,)[i-1])]
        #         success_messages.append(f"{data_type}: {', '.join(arm_received)}")
        
        # ä»è‡‚æ•°æ®çŠ¶æ€
        arm_data_types = ["ä»è‡‚å…³èŠ‚è§’åº¦",]
        for i, data_type in enumerate(arm_data_types, 1):
            if conditions[i][0]():
                arm_received = [
                    name for name in self.follower_motors 
                    if any(name in key for key in (self.robot_socket.arm_joint_data,)[i-1])
                    or any(name in key for key in (self.robot_socket.gripper_data,)[i-1])
                    or any(name in key for key in (self.robot_socket.leg_data,)[i-1])
                    or any(name in key for key in (self.robot_socket.head_data,)[i-1])
                ]
                success_messages.append(f"{data_type}: {', '.join(arm_received)}")
        
        # æ‰“å°æˆåŠŸè¿æ¥ä¿¡æ¯
        print("\n[è¿æ¥æˆåŠŸ] æ‰€æœ‰è®¾å¤‡å·²å°±ç»ª:")
        for msg in success_messages:
            print(f"  - {msg}")
        print(f"  æ€»è€—æ—¶: {time.perf_counter() - start_time:.2f}ç§’\n")
        # ===========================

        self.is_connected = True
    
    @property
    def features(self):
        return {**self.motor_features, **self.camera_features}

    @property
    def has_camera(self):
        return len(self.cameras) > 0

    @property
    def num_cameras(self):
        return len(self.cameras)

    def teleop_step(
        self, record_data=False, 
    ) -> None | tuple[dict[str, torch.Tensor], dict[str, torch.Tensor]]:

        if not self.is_connected:
            raise RobotDeviceNotConnectedError(
                "Aloha is not connected. You need to run `robot.connect()`."
            )

        if not record_data:
            return

        follower_joint = {}
        for name in self.follower_motors:
            now = time.perf_counter()
            
            # æŸ¥æ‰¾åŒ¹é…çš„å…³èŠ‚æ•°æ®
            match_name = None
            for potential_match in self.robot_socket.arm_joint_data:
                if name in potential_match:
                    match_name = potential_match
                    break
            
            if match_name is None:
                continue  # å¦‚æœæ²¡æœ‰åŒ¹é…é¡¹åˆ™è·³è¿‡
            
            try:
                # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä¸€æ¬¡æ€§æ„å»ºæ•°ç»„
                joint_data = self.robot_socket.arm_joint_data[match_name]
                positions = [value["position"] for value in joint_data.values()]
                
                # ç›´æ¥ä½¿ç”¨torchä»åˆ—è¡¨åˆ›å»ºå¼ é‡
                byte_array = torch.tensor(positions, dtype=torch.float32)
                
                follower_joint[name] = byte_array
                
            except Exception as e:
                print(f"Error processing joint data for {name}: {e}")
                continue
            
            self.logs[f"read_follower_{name}_joint_dt_s"] = time.perf_counter() - now

        follower_gripper = {}
        for name in self.follower_motors:
            now = time.perf_counter()
            
            # æŸ¥æ‰¾åŒ¹é…çš„å…³èŠ‚æ•°æ®
            match_name = None
            for potential_match in self.robot_socket.gripper_data:
                if name in potential_match:
                    match_name = potential_match
                    break
            
            if match_name is None:
                continue  # å¦‚æœæ²¡æœ‰åŒ¹é…é¡¹åˆ™è·³è¿‡
            
            try:
                # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä¸€æ¬¡æ€§æ„å»ºæ•°ç»„
                joint_data = self.robot_socket.gripper_data[match_name]
                positions = [value["position"] for value in joint_data.values()]
                
                # ç›´æ¥ä½¿ç”¨torchä»åˆ—è¡¨åˆ›å»ºå¼ é‡
                byte_array = torch.tensor(positions, dtype=torch.float32)
                byte_array = byte_array / 100.0
                
                follower_gripper[name] = byte_array
                
            except Exception as e:
                print(f"Error processing joint data for {name}: {e}")
                continue
            
            self.logs[f"read_follower_{name}_joint_dt_s"] = time.perf_counter() - now


        follower_leg = {}
        for name in self.follower_motors:
            now = time.perf_counter()
            
            # æŸ¥æ‰¾åŒ¹é…çš„å…³èŠ‚æ•°æ®
            match_name = None
            for potential_match in self.robot_socket.leg_data:
                if name in potential_match:
                    match_name = potential_match
                    break
            
            if match_name is None:
                continue  # å¦‚æœæ²¡æœ‰åŒ¹é…é¡¹åˆ™è·³è¿‡
            
            try:
                # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä¸€æ¬¡æ€§æ„å»ºæ•°ç»„
                joint_data = self.robot_socket.leg_data[match_name]
                positions = [value["position"] for value in joint_data.values()]
                
                # ç›´æ¥ä½¿ç”¨torchä»åˆ—è¡¨åˆ›å»ºå¼ é‡
                byte_array = torch.tensor(positions, dtype=torch.float32)
                
                follower_leg[name] = byte_array
                
            except Exception as e:
                print(f"Error processing joint data for {name}: {e}")
                continue
            
            self.logs[f"read_follower_{name}_joint_dt_s"] = time.perf_counter() - now

        follower_head = {}
        for name in self.follower_motors:
            now = time.perf_counter()
            
            # æŸ¥æ‰¾åŒ¹é…çš„å…³èŠ‚æ•°æ®
            match_name = None
            for potential_match in self.robot_socket.head_data:
                if name in potential_match:
                    match_name = potential_match
                    break
            
            if match_name is None:
                continue  # å¦‚æœæ²¡æœ‰åŒ¹é…é¡¹åˆ™è·³è¿‡
            
            try:
                # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä¸€æ¬¡æ€§æ„å»ºæ•°ç»„
                joint_data = self.robot_socket.head_data[match_name]
                positions = [value["position"] for value in joint_data.values()]
                
                # ç›´æ¥ä½¿ç”¨torchä»åˆ—è¡¨åˆ›å»ºå¼ é‡
                byte_array = torch.tensor(positions, dtype=torch.float32)
                
                follower_head[name] = byte_array
                
            except Exception as e:
                print(f"Error processing joint data for {name}: {e}")
                continue
            
            self.logs[f"read_follower_{name}_joint_dt_s"] = time.perf_counter() - now

                    
        # leader_joint = {}
        # for name in self.leader_arms:
        #     for match_name in recv_joint:
        #         if name in match_name:
        #             now = time.perf_counter()

        #             byte_array = np.zeros(6, dtype=np.float32)
        #             pose_read = recv_joint[match_name]

        #             byte_array[:6] = pose_read[:]
        #             byte_array = np.round(byte_array, 3)
                    
        #             leader_joint[name] = torch.from_numpy(byte_array)

        #             self.logs[f"read_leader_{name}_joint_dt_s"] = time.perf_counter() - now

        #è®°å½•å½“å‰å…³èŠ‚è§’åº¦
        state = []
        for name in self.follower_motors:
            if name in follower_joint:
                state.append(follower_joint[name])
            if name in follower_gripper:
                state.append(follower_gripper[name])
            if name in follower_leg:
                state.append(follower_leg[name])
            if name in follower_head:
                state.append(follower_head[name])
        state = torch.cat(state)

        #å°†å…³èŠ‚ç›®æ ‡ä½ç½®æ·»åŠ åˆ° action åˆ—è¡¨ä¸­
        action = []
        for name in self.follower_motors:
            if name in follower_joint:
                action.append(follower_joint[name])
            if name in follower_gripper:
                action.append(follower_gripper[name])
            if name in follower_leg:
                action.append(follower_leg[name])
            if name in follower_head:
                action.append(follower_head[name])
        action = torch.cat(action)

        # Capture images from cameras
        images = {}
        for name, camera in self.cameras.items():
            now = time.perf_counter()
            
            images[name] = self.robot_socket.get_latest_image(camera.topic)
            images[name] = torch.from_numpy(images[name])
            self.logs[f"read_camera_{name}_dt_s"] = time.perf_counter() - now

        # Populate output dictionnaries and format to pytorch
        obs_dict, action_dict = {}, {}
        obs_dict["observation.state"] = state
        action_dict["action"] = action
        for name in self.cameras:
            obs_dict[f"observation.images.{name}"] = images[name]

        # print("end teleoperate record")
        return obs_dict, action_dict

    # def send_action(self, action: dict[str, Any]):
    #     """The provided action is expected to be a vector."""
    #     if not self.is_connected:
    #         raise RobotDeviceNotConnectedError(
    #             "KochRobot is not connected. You need to run `robot.connect()`."
    #         )

    #     for name in self.leader_arms:
    #         goal_joint = [ val for key, val in action.items() if name in key and "joint" in key]
    #         # goal_gripper = [ val for key, val in action.items() if name in key and "gripper" in key]

    #         # goal_joint = action[(arm_index*arm_action_dim+from_idx):(arm_index*arm_action_dim+to_idx)]
    #         # goal_gripper = action[arm_index*arm_action_dim + 12]
    #         # arm_index += 1
    #         goal_joint_numpy = np.array([t.item() for t in goal_joint], dtype=np.float32)
    #         # goal_gripper_numpy = np.array([t.item() for t in goal_gripper], dtype=np.float32)
    #         # position = np.concatenate([goal_joint_numpy, goal_gripper_numpy], axis=0)

    #         so101_zmq_send(f"action_joint_{name}", goal_joint_numpy, wait_time_s=0.01)

    def disconnect(self):
        if not self.is_connected:
            raise RobotDeviceNotConnectedError(
                "Aloha is not connected. You need to run `robot.connect()` before disconnecting."
            )

        self.is_connected = False
        self.robot_socket.shutdown()


    def __del__(self):
        if getattr(self, "is_connected", False):
            self.disconnect()


# ç›‘æ§æœºå™¨äººçŠ¶æ€çš„ç‹¬ç«‹å‡½æ•°
def monitor_robot_status(robot_socket: RobotSocket, update_interval: float = 1.0):
    """ç›‘æ§æœºå™¨äººçŠ¶æ€å¹¶æ‰“å°ä¿¡æ¯"""
    topic_to_window = {
        "/right_arm_camera/color/image_raw": "Right Arm Camera",
        "/left_arm_camera/color/image_raw": "Left Arm Camera",
        "/front_head_camera/right_color/image_raw": "Front Head Right Camera",
        "/front_head_camera/left_color/image_raw": "Front Head Left Camera",
    }
    
    while robot_socket.running:
        try:
            # æ‰“å°çŠ¶æ€
            topics = robot_socket.get_all_topics()
            logger.info(f"ğŸ“Š å½“å‰æ´»è·ƒä¸»é¢˜: {len(topics)}ä¸ª")

            # æ‰“å°å…³èŠ‚æ•°æ®
            right_arm = robot_socket.get_arm_state("right")
            left_arm = robot_socket.get_arm_state("left")
            right_gripper = robot_socket.get_gripper_state("right")
            left_gripper = robot_socket.get_gripper_state("left")

            print("\n=== ğŸ¤– å®æ—¶å…³èŠ‚çŠ¶æ€ ===")
            if right_arm:
                pos_str = ", ".join([f"{k}: {v['position']:.4f}" for k, v in right_arm.items()])
                print(f"ğŸ‘‰ å³è‡‚: {pos_str}")
            if left_arm:
                pos_str = ", ".join([f"{k}: {v['position']:.4f}" for k, v in left_arm.items()])
                print(f"ğŸ‘ˆ å·¦è‡‚: {pos_str}")
            if right_gripper:
                pos_str = ", ".join([f"{k}: {v['position']:.4f}" for k, v in right_gripper.items()])
                print(f"âœ‹ å³å¤¹çˆª: {pos_str}")
            if left_gripper:
                pos_str = ", ".join([f"{k}: {v['position']:.4f}" for k, v in left_gripper.items()])
                print(f"âœ‹ å·¦å¤¹çˆª: {pos_str}")

            time.sleep(update_interval)
        except Exception as e:
            logger.error(f"ç›‘æ§çº¿ç¨‹é”™è¯¯: {e}")
            time.sleep(update_interval)